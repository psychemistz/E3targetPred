{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## All required packages\n",
    "## Scientific Packakges\n",
    "import sys, os, re, gc, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "from scipy.io import savemat\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Keras\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "## Sklearn-metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "## Custom functions\n",
    "from models import E3_LSE\n",
    "from utils import *\n",
    "from feature_encodings import * ## Feature encoding utils\n",
    "from perf_metrics import * ## Some of hand crafted performance metrics\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading and pre-processing E3-Target dataset\n",
    "data_path = 'https://raw.githubusercontent.com/psychemistz/Colab_temp/master/E3target_pred/1metadata.csv'\n",
    "dataset = pd.read_csv(data_path, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract features\n",
    "E3_features, Sub_features, Pair_features = Extract_Features(dataset, gap_size=6)\n",
    "target_label = to_categorical(dataset['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MCSim(LVs, Gaps, lmd, num_Trials, E3_features, Sub_features, Pair_features, target_label):\n",
    "#     ##### Perform Monte-Carlos Simulations for [num_Trials]# of independent Trials####\n",
    "    \n",
    "#     ## Define parameters explicitly\n",
    "#     start = time.time()\n",
    "#     LVs = LVs\n",
    "#     Gaps = Gaps\n",
    "#     lmd = lmd\n",
    "#     num_Trials = num_Trials\n",
    "    \n",
    "#     print(\"start MC Simulation\")\n",
    "    \n",
    "#     ## Start loops    \n",
    "#     for gap in Gaps:\n",
    "#         for LV in LVs:\n",
    "#             Stats =[]            \n",
    "#             ## Divide negative and positive samples\n",
    "#             plist = list(np.asarray(np.where(target_label[:,1]==1)).flatten())\n",
    "#             nlist = list(np.asarray(np.where(target_label[:,1]==0)).flatten())\n",
    "            \n",
    "#             for loop_ind in range(0,num_Trials):\n",
    "#                 ## Split Datasets\n",
    "#                 train_list, val_list, test_list = split_dataset(plist, nlist, target_label, num_train=570, num_valid=30)\n",
    "                \n",
    "#                 ## Load Datasets\n",
    "#                 Xin_train, Xout_train, y_train = load_dataset(E3_features, Sub_features, Pair_features, target_label, train_list)\n",
    "#                 Xin_val, Xout_val, y_val = load_dataset(E3_features, Sub_features, Pair_features, target_label, val_list)\n",
    "#                 Xin_test, Xout_test, y_test = load_dataset(E3_features, Sub_features, Pair_features, target_label, test_list)\n",
    "                \n",
    "#                 # Define Model\n",
    "#                 model = E3_LSE(input_size=Xin_train.shape[1],output_size=Xout_train.shape[1],LV=LV, lmd=lmd)\n",
    "#                 es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=300)\n",
    "                \n",
    "#                 checkpoint = ModelCheckpoint('mc_model-best.h5',\n",
    "#                                              verbose=0, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "                \n",
    "#                 history = model.fit({'enc_input': Xin_train},\n",
    "#                                     {'class_output': y_train, 'decoder_output': Xout_train},\n",
    "#                                     validation_data = ({'enc_input': Xin_val},\n",
    "#                                                        {'class_output': y_val, 'decoder_output': Xout_val}),\n",
    "#                                     epochs=2000, batch_size=1000, callbacks=[checkpoint, es], verbose=0)\n",
    "                \n",
    "#                 del model  # deletes the existing model\n",
    "#                 model = load_model('mc_model-best.h5')\n",
    "                \n",
    "#                 ## Calculate Outputs\n",
    "#                 y_train_pred, X_train_pred = model.predict(Xin_train,batch_size=1800, verbose=0)\n",
    "#                 y_train_pred = to_categorical(y_train_pred.argmax(axis=1))\n",
    "#                 MSE_X_train_pred = (np.square(X_train_pred - Xout_train)).mean(axis=1)\n",
    "                \n",
    "#                 y_val_pred, X_val_pred = model.predict(Xin_val,batch_size=200, verbose=0)\n",
    "#                 y_val_pred = to_categorical(y_val_pred.argmax(axis=1))\n",
    "#                 MSE_X_val_pred = (np.square(X_val_pred - Xout_val)).mean(axis=1)\n",
    "                \n",
    "#                 y_test_pred, X_test_pred = model.predict(Xin_test,batch_size=200, verbose=0)\n",
    "#                 y_test_pred = to_categorical(y_test_pred.argmax(axis=1))\n",
    "#                 MSE_X_test_pred = (np.square(X_test_pred - Xout_test)).mean(axis=1)\n",
    "                \n",
    "#                 ## Performance Measures\n",
    "#                 tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi, tr_auc = Calculate_Stats(y_train,y_train_pred);\n",
    "#                 v_acc, v_sen, v_spe, v_f1, v_mcc, v_bacc, v_yi, v_auc = Calculate_Stats(y_val,y_val_pred);\n",
    "#                 t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi, t_auc = Calculate_Stats(y_test,y_test_pred);\n",
    "\n",
    "#                 ## Save Measures for later analysis\n",
    "#                 Stats.append([tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi, tr_auc, -10*np.log10(MSE_X_train_pred.mean()),\n",
    "#                               v_acc, v_sen, v_spe, v_f1, v_mcc, v_bacc, v_yi, v_auc, -10*np.log10(MSE_X_val_pred.mean()),\n",
    "#                               t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi, t_auc, -10*np.log10(MSE_X_test_pred.mean())])\n",
    "                \n",
    "#                 ## Print performance messages\n",
    "#                 print('CKSAAP-Gap:',gap, 'LV=',LV,'Trial:',loop_ind, 'Test Youden-index:', t_yi, 'MCC:', t_mcc, 'AUC:', t_auc, 'MSE (dB):', -10*np.log10(MSE_X_test_pred.mean()))\n",
    "#                 ## End of single trial\n",
    "            \n",
    "#             ## save all trials\n",
    "#             Statistics = np.asarray(Stats)\n",
    "#             filename = 'E3_LSE_STATS_CKSAAP_GAP_' + str(gap) + 'LV' + str(LV) + 'cls' + str(0.99) +'.mat'\n",
    "#             savemat(filename,{'Statistics':Statistics})\n",
    "                \n",
    "#         ## Show Classification/Reconstruction Statistics for given LV and gap\n",
    "#         Show_Statistics('Training Results (MEAN)',Statistics.mean(axis=0)[0:9])\n",
    "#         Show_Statistics('Validation Results (MEAN)',Statistics.mean(axis=0)[9:18])\n",
    "#         Show_Statistics('Test Results (MEAN)',Statistics.mean(axis=0)[18:27])\n",
    "            \n",
    "#     end = time.time()\n",
    "#     print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKSAAP-Gap: 0 LV= 2 Trial: 0 Test Youden-index: 0.4566707953640625 MCC: 0.32896427251312305 AUC: 0.7283353976820313 MSE (dB): 21.17294480866242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3e967d72166b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mnum_Trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mMCSim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLVs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGaps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_Trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE3_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSub_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPair_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\개인연구\\2020-1E3TargetPred\\scripts\\utils.py\u001b[0m in \u001b[0;36mMCSim\u001b[1;34m(LVs, Gaps, lmd, num_Trials, E3_features, Sub_features, Pair_features, target_label)\u001b[0m\n\u001b[0;32m     76\u001b[0m                                     validation_data = ({'enc_input': Xin_val},\n\u001b[0;32m     77\u001b[0m                                                        {'class_output': y_val, 'decoder_output': Xout_val}),\n\u001b[1;32m---> 78\u001b[1;33m                                     epochs=2000, batch_size=1000, callbacks=[checkpoint, es], verbose=0)\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[1;31m# deletes the existing model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m             \u001b[0mval_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_test_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_updates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                 **self._function_kwargs)\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[0;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3009\u001b[1;33m                                      **kwargs)\n\u001b[0m\u001b[0;32m   3010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   3758\u001b[0m       raise ValueError('Session keyword arguments are not support during '\n\u001b[0;32m   3759\u001b[0m                        'eager execution. You passed: %s' % (kwargs,))\n\u001b[1;32m-> 3760\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mEagerExecutionFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3762\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, name)\u001b[0m\n\u001b[0;32m   3655\u001b[0m             \u001b[0madd_sources\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3656\u001b[0m             \u001b[0mhandle_captures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3657\u001b[1;33m             base_graph=source_graph)\n\u001b[0m\u001b[0;32m   3658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3659\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlifted_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\tensorflow_core\\python\\eager\\lift_to_graph.py\u001b[0m in \u001b[0;36mlift_to_graph\u001b[1;34m(tensors, graph, sources, disallowed_placeholders, add_sources, handle_captures, base_graph, op_map)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m       new_input_mutations, new_control_mutations = _copy_non_source(\n\u001b[1;32m--> 339\u001b[1;33m           op=op, graph=graph, op_map=op_map, base_graph=base_graph)\n\u001b[0m\u001b[0;32m    340\u001b[0m       \u001b[0minput_mutations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_input_mutations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[0mcontrol_mutations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_control_mutations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\E3targetPred\\lib\\site-packages\\tensorflow_core\\python\\eager\\lift_to_graph.py\u001b[0m in \u001b[0;36m_copy_non_source\u001b[1;34m(op, graph, op_map, base_graph)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mdtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         attrs={\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_class\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_tpu_replicate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"LVs = Number of Latent Variables\n",
    "   Gaps = Number of Gaps in CKSAAP Feature\n",
    "   lmd = Weight of Reconstruction Loss (Lambda)\n",
    "   num_Trials = Number of Trials for each LV, Gap combination at given Lambda value. \n",
    "\"\"\"\n",
    "LVs = np.asarray(range(2,6))\n",
    "Gaps = np.asarray(range(0,9))\n",
    "lmd = 0.5 \n",
    "num_Trials = 1\n",
    "\n",
    "MCSim(LVs, Gaps, lmd, num_Trials, E3_features, Sub_features, Pair_features, target_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
